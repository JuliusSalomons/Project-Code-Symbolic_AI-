{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Code**\n",
        "\n",
        "**By:** Julius Salomons <br>\n",
        "**Student number:** 14039559 <br>\n",
        "**Date:** (19-11-2024) 22 december 2024 <br>\n",
        "**Course:** Symbolic and Neural AI <br> <br>\n",
        "\n",
        "**Task description** <br>\n",
        "This project focuses on a classification task: predicting whether a customer will churn (leave the service) based on their data. The aim is to develop and compare the performance of two models to determine which is better suited for this task. <br>  <br>\n",
        "\n",
        "**Dataset description** <br>\n",
        "- https://www.kaggle.com/code/ybifoundation/telecom-customer-churn-prediction  <br>\n",
        "- 7043 rows and 21 columns, making it manageable for computation on a standard\n",
        "laptop. <br>\n",
        "- Fairly balanced dataset (based on churning rates) <br> <br>\n",
        "\n",
        "**Models**  <br>\n",
        "1. Logic tensor network (LTN)  <br>\n",
        "2. Nearest Neighbors Classification (NN) <br>\n",
        "\n",
        "Model 1 is covered in this course. <br>\n",
        "Model 2 (https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighborsclassification) is a traditional machine learning model that I am already familiar with. <br>  <br>\n",
        "\n",
        "**Investigation description** <br>\n",
        "This investigation will compare model performance using metrics like accuracy, precision, recall, and F1-score. By examining these metrics, we can gain insight into how well each model predicts customer churn. The comparison will provide a deeper understanding of the strengths and limitations of a neural-symbolic approach (LTN) and a traditional machine learning model (NN). <br> <br>\n",
        "\n",
        "**Expected Outcomes**  <br>\n",
        "I expect Nearest Neighbors to outperform the LTN due to its proven effectiveness in handling classification tasks with similar feature structures. However, I anticipate the difference in performance may not be substantial."
      ],
      "metadata": {
        "id": "4THZBkm2gdXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "lp1FRTYXhcGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url = \"https://raw.githubusercontent.com/dsrscientist/DSData/master/Telecom_customer_churn.csv\"  # Update if necessary\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "# displays basic info about the dataset\n",
        "print(\"Dataset Head:\\n\", data.head())\n",
        "\n",
        "# Handle missing values if any\n",
        "data = data.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayvFFmTvhfww",
        "outputId": "fc2e346e-ce16-49bf-d4e4-fe68074403c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Head:\n",
            "    customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
            "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
            "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
            "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
            "3  7795-CFOCW    Male              0      No         No      45           No   \n",
            "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
            "\n",
            "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
            "0  No phone service             DSL             No  ...               No   \n",
            "1                No             DSL            Yes  ...              Yes   \n",
            "2                No             DSL            Yes  ...               No   \n",
            "3  No phone service             DSL            Yes  ...              Yes   \n",
            "4                No     Fiber optic             No  ...               No   \n",
            "\n",
            "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
            "0          No          No              No  Month-to-month              Yes   \n",
            "1          No          No              No        One year               No   \n",
            "2          No          No              No  Month-to-month              Yes   \n",
            "3         Yes          No              No        One year               No   \n",
            "4          No          No              No  Month-to-month              Yes   \n",
            "\n",
            "               PaymentMethod MonthlyCharges  TotalCharges Churn  \n",
            "0           Electronic check          29.85         29.85    No  \n",
            "1               Mailed check          56.95        1889.5    No  \n",
            "2               Mailed check          53.85        108.15   Yes  \n",
            "3  Bank transfer (automatic)          42.30       1840.75    No  \n",
            "4           Electronic check          70.70        151.65   Yes  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Nearest neigbours code**"
      ],
      "metadata": {
        "id": "oZooGXCchx3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encode categorical variables\n",
        "label_encoders = {}\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "# separate features and target\n",
        "target_column = 'Churn'\n",
        "X = data.drop(columns=[target_column])\n",
        "y = data[target_column]\n",
        "\n",
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "rNqIoPDpjoXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9aNlEzVgaFM"
      },
      "outputs": [],
      "source": [
        "# train Nearest Neighbors Classifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = knn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26qyD1TnjjC1",
        "outputId": "661d2584-e47c-4ae9-ec24-f19ccafd8e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation:\n",
            "Accuracy: 0.7729\n",
            "Precision: 0.5810\n",
            "Recall: 0.5094\n",
            "F1 Score: 0.5429\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85      1036\n",
            "           1       0.58      0.51      0.54       373\n",
            "\n",
            "    accuracy                           0.77      1409\n",
            "   macro avg       0.71      0.69      0.70      1409\n",
            "weighted avg       0.76      0.77      0.77      1409\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LTN code**\n",
        "\n",
        "1e poging is van de stof van week 3"
      ],
      "metadata": {
        "id": "VDV3IOgOiKOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ltntorch\n",
        "import ltn\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "SDzjdxsWhxLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/dsrscientist/DSData/master/Telecom_customer_churn.csv\"  # Update if necessary\n",
        "data = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "BrUBuZwNi31V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing\n",
        "data = data.dropna()\n",
        "label_encoders = {}\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    le = LabelEncoder()\n",
        "    data[column] = le.fit_transform(data[column])\n",
        "    label_encoders[column] = le\n",
        "\n",
        "X = data.drop(columns=['Churn'])\n",
        "y = data['Churn']\n",
        "\n",
        "# split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# convert to pyTorch tensors\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "IQ57jzT5iSHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the feedforward neural network\n",
        "class ModelP2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelP2, self).__init__()\n",
        "        self.elu = nn.ELU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.dense1 = nn.Linear(X_train.shape[1], 5)\n",
        "        self.dense2 = nn.Linear(5, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.elu(self.dense1(x))\n",
        "        return self.sigmoid(self.dense2(x))\n",
        "\n",
        "# wrap the model in LTN.Predicate\n",
        "modelP2 = ModelP2()\n",
        "P2 = ltn.Predicate(model=modelP2)\n",
        "\n",
        "# loss function for LTN\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Define an optimizer\n",
        "optimizer = optim.Adam(modelP2.parameters(), lr=0.01)\n",
        "\n",
        "# training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    modelP2.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    predictions = modelP2(X_train)\n",
        "    loss = criterion(predictions, y_train)\n",
        "\n",
        "    # backward pass and optimization\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # log progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ3mz6Byi8xu",
        "outputId": "373ddd33-d5f0-4d19-f47e-5cad195b3101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 0.6036\n",
            "Epoch [20/100], Loss: 0.5232\n",
            "Epoch [30/100], Loss: 0.4765\n",
            "Epoch [40/100], Loss: 0.4487\n",
            "Epoch [50/100], Loss: 0.4373\n",
            "Epoch [60/100], Loss: 0.4306\n",
            "Epoch [70/100], Loss: 0.4261\n",
            "Epoch [80/100], Loss: 0.4224\n",
            "Epoch [90/100], Loss: 0.4194\n",
            "Epoch [100/100], Loss: 0.4174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "modelP2.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = modelP2(X_test)\n",
        "    y_pred_class = (y_pred > 0.5).float()\n",
        "\n",
        "# convert predictions and labels to numpy arrays\n",
        "y_test_np = y_test.numpy()\n",
        "y_pred_class_np = y_pred_class.numpy()\n",
        "\n",
        "# calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test_np, y_pred_class_np)\n",
        "precision = precision_score(y_test_np, y_pred_class_np)\n",
        "recall = recall_score(y_test_np, y_pred_class_np)\n",
        "f1 = f1_score(y_test_np, y_pred_class_np)\n",
        "\n",
        "# print the evaluation results\n",
        "print(\"\\nModel Evaluation:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "# detailed classification report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test_np, y_pred_class_np))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH84eSsnjWgq",
        "outputId": "24b3c062-d4c3-44e5-efde-262b58f888bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Evaluation:\n",
            "Accuracy: 0.8197\n",
            "Precision: 0.6854\n",
            "Recall: 0.5898\n",
            "F1 Score: 0.6340\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.86      0.90      0.88      1036\n",
            "         1.0       0.69      0.59      0.63       373\n",
            "\n",
            "    accuracy                           0.82      1409\n",
            "   macro avg       0.77      0.75      0.76      1409\n",
            "weighted avg       0.81      0.82      0.82      1409\n",
            "\n"
          ]
        }
      ]
    }
  ]
}